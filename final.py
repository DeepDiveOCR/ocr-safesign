import requests
import pandas as pd
import numpy as np
from xml.etree import ElementTree as ET
from datetime import datetime, timedelta
from math import radians, sin, cos, sqrt, atan2
from sklearn.neighbors import BallTree

def parse_address(address):
    """
    êµ¬, ë™, ì§€ë²ˆì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” ë²”ìš© ì£¼ì†Œ íŒŒì„œ
    ì˜ˆ: 'ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ ë…¼í˜„ë™ 203-1' â†’ ('ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬', 'ë…¼í˜„ë™', '203-1')
    """
    tokens = address.strip().split()

    # êµ¬ or êµ° ì°¾ê¸°
    gu_index = next((i for i, t in enumerate(tokens) if t.endswith("êµ¬") or t.endswith("êµ°")), None)

    region_name = " ".join(tokens[:gu_index + 1])      # ì˜ˆ: ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬
    umdNm = tokens[gu_index + 1]                        # ì˜ˆ: ë…¼í˜„ë™
    jibun = tokens[gu_index + 2]                        # ì˜ˆ: 203-1

    return region_name, umdNm, jibun

# âœ… ì§€ì—­ëª… â†’ ë²•ì •ë™ì½”ë“œ(ì• 5ìë¦¬) ë³€í™˜ í•¨ìˆ˜
def get_region_prefix(region_name):
    url = "http://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList"
    
    params = {
        'ServiceKey': "7vMdnzTpnFnBO5wPN3LkHyPgPNFu3A/w/+RH8EJw3ihZfuhA5UiMx4x/PYl1qjlCx1VAzTL+i2GJXf1c/oHfyg==",
        'type': 'json',
        'pageNo': '1',
        'numOfRows': '1000',
        'flag': 'Y',
        'locatadd_nm': region_name
    }

    response = requests.get(url, params=params)

    if response.status_code == 200:
        data = response.json()
        stanregin = data.get('StanReginCd', [])

        for item in stanregin:
            if 'row' in item:
                for entry in item['row']:
                    if entry.get('locatadd_nm') == region_name:
                        return entry['region_cd'][:5]  # ì• 5ìë¦¬ (ë²•ì •ë™ì½”ë“œ ìƒìœ„)
        print("âŒ í•´ë‹¹ ì§€ì—­ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    else:
        print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {response.status_code}")
        return None

# ê±´ë¬¼ ìœ í˜•ë³„ api url
def get_trade_api_url(building_type):
    mapping = {
        "ì•„íŒŒíŠ¸": "AptTrade",
        "ë‹¤ì„¸ëŒ€": "RHTrade",
        "ì—°ë¦½": "RHTrade",
        "ì˜¤í”¼ìŠ¤í…”": "OffiTrade"
    }
    api_type = mapping.get(building_type)
    if api_type:
        return f"https://apis.data.go.kr/1613000/RTMSDataSvc{api_type}/getRTMSDataSvc{api_type}"
    return None

# âœ… ì‹¤ê±°ë˜ê°€ API í˜¸ì¶œ
def get_trade_deals(lawd_cd, target_dong, target_jibun, months, building_type):
    url = get_trade_api_url(building_type)
    today = datetime.today()
    month_list = [(today - timedelta(days=30 * i)).strftime("%Y%m") for i in range(months)]
    all_data = []

    for yyyymm in month_list:
        params = {
            "serviceKey": "7vMdnzTpnFnBO5wPN3LkHyPgPNFu3A/w/+RH8EJw3ihZfuhA5UiMx4x/PYl1qjlCx1VAzTL+i2GJXf1c/oHfyg==",
            "LAWD_CD": lawd_cd,
            "DEAL_YMD": yyyymm,
            "numOfRows": "1000",
            "pageNo": "1"
        }
        try:
            response = requests.get(url, params=params)
            root = ET.fromstring(response.content)

            for item in root.iter("item"):
                dong = item.findtext("umdNm", "").strip()
                api_jibun = item.findtext("jibun", "").strip()
                
                if dong != target_dong or api_jibun != target_jibun:
                    continue

                deal_amount_raw = item.findtext("dealAmount")
                area_raw = item.findtext("excluUseAr")
                year = item.findtext("dealYear")
                month = item.findtext("dealMonth")
                day = item.findtext("dealDay")

                if not (deal_amount_raw and area_raw and year and month and day):
                    continue

                deal_amount = int(deal_amount_raw.replace(",", "")) * 10000
                area = float(area_raw)
                date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
                all_data.append({
                    "ê±°ë˜ê¸ˆì•¡": deal_amount,
                    "ì „ìš©ë©´ì ": area,
                    "ê³„ì•½ì¼": date
                })
        except Exception as e:
            print(f"âŒ API ì˜¤ë¥˜: {e}")
            continue

    return pd.DataFrame(all_data)

# âœ… í†µí•© ì‹œì„¸ ì¶”ì • í•¨ìˆ˜
def estimate_real_estate_price(lawd_cd, target_dong, target_jibun, building_type, fallback_callback=None):
    def fetch_and_estimate(months, label):
        df = get_trade_deals(lawd_cd, target_dong, target_jibun, months, building_type)
        if len(df) >= 5:
            df["ã¡ë‹¹ê°€ê²©"] = df["ê±°ë˜ê¸ˆì•¡"] / df["ì „ìš©ë©´ì "]
            median = df["ã¡ë‹¹ê°€ê²©"].median()
            print(f"âœ… {label} ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì„¸ë¥¼ ê³„ì‚°í•˜ì˜€ìŠµë‹ˆë‹¤.")
            return round(median), label
        return None, None

    # 1ï¸âƒ£ ìµœê·¼ 1ë…„
    price, ê¸°ì¤€ = fetch_and_estimate(12, "1ë…„ ê¸°ì¤€")
    if price is not None:
        return price, ê¸°ì¤€

    # 2ï¸âƒ£ ìµœê·¼ 2ë…„
    price, ê¸°ì¤€ = fetch_and_estimate(24, "2ë…„ ê¸°ì¤€")
    if price is not None:
        print("âš ï¸ ìµœê·¼ ê±°ë˜ê°€ ë¶€ì¡±í•˜ì—¬ ìµœê·¼ 2ë…„ê°„ ë°ì´í„°ë¥¼ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.")
        return price, ê¸°ì¤€

    # 3ï¸âƒ£ ëŒ€ì²´ ì „ëµ (ì¸ê·¼ ë‹¨ì§€ ë“±)
    if fallback_callback:
        price = fallback_callback()
        print("âš ï¸ 2ë…„ê°„ ë°ì´í„°ë„ ë¶€ì¡±í•˜ì—¬ ì¸ê·¼ ë‹¨ì§€ ê¸°ë°˜ìœ¼ë¡œ ì‹œì„¸ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.")
        return round(price), "ì¸ê·¼ ë‹¨ì§€"

    print("âŒ ì‹œì„¸ë¥¼ ì¶”ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return None, "ë°ì´í„° ë¶€ì¡±"


### fallback
def load_coords_by_building_type(building_type):
    file_mapping = {
        "ì˜¤í”¼ìŠ¤í…”": "df_office.csv",
        "ì•„íŒŒíŠ¸" : "df_apartment.csv",
        "ë‹¤ì„¸ëŒ€": "df_villa.csv"
    }
    filepath = file_mapping.get(building_type)
    return pd.read_csv(filepath)

def get_coords(address):
    kakao_api_key = "6665946ef83bd1dc889184a24cf212a2"
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {kakao_api_key}"}
    params = {"query": address}

    response = requests.get(url, headers=headers, params=params)
    if response.status_code == 200:
        result = response.json()
        if result['documents']:
            x = float(result['documents'][0]['x'])  # longitude
            y = float(result['documents'][0]['y'])  # latitude
            return y, x
        else:
            print("âŒ ì£¼ì†Œì— ëŒ€í•œ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
    else:
        print(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
        return None, None
    
def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0  # ì§€êµ¬ ë°˜ì§€ë¦„(km)
    dlat = radians(lat2 - lat1)
    dlon = radians(lon2 - lon1)
    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R * c

def weighted_median(values, weights):
    sorted_idx = np.argsort(values)
    sorted_values = np.array(values)[sorted_idx]
    sorted_weights = np.array(weights)[sorted_idx]
    cumulative_weight = np.cumsum(sorted_weights)
    cutoff = 0.5 * sum(sorted_weights)
    return sorted_values[cumulative_weight >= cutoff][0]

def fallback_strategy(address, lawd_cd, df_coords, building_type, months=24):
    # 1ï¸âƒ£ ì£¼ì†Œ â†’ ìœ„ë„, ê²½ë„
    lat, lon = get_coords(address)

    # 2ï¸âƒ£ ê±°ë¦¬ ê³„ì‚°
    df_coords["ê±°ë¦¬_km"] = df_coords.apply(
        lambda row: haversine(lat, lon, row["ìœ„ë„"], row["ê²½ë„"]),
        axis=1
    )

    # 3ï¸âƒ£ ì¸ì ‘ ë‹¨ì§€ 1km ì´ë‚´ ìƒìœ„ 10ê°œ ì„ íƒ
    nearby_df = df_coords[df_coords["ê±°ë¦¬_km"] <= 1].sort_values(by="ê±°ë¦¬_km").head(10)
    deal_list = []

    for _, row in nearby_df.iterrows():
        full_address = row["ì „ì²´ì£¼ì†Œ"]
        _, dong, jibun = parse_address(full_address)

        deals = get_trade_deals(lawd_cd, dong, jibun, months, building_type)
        if not deals.empty:
            deals["ê±°ë¦¬_km"] = row["ê±°ë¦¬_km"]
            deal_list.append(deals)

    # 4ï¸âƒ£ ì‹œì„¸ ê³„ì‚° (ê°€ì¤‘ ì¤‘ì•™ê°’)
    combined = pd.concat(deal_list, ignore_index=True)
    combined["ã¡ë‹¹ê°€ê²©"] = combined["ê±°ë˜ê¸ˆì•¡"] / combined["ì „ìš©ë©´ì "]

    today = pd.Timestamp.today()
    combined["ê³„ì•½ì¼"] = pd.to_datetime(combined["ê³„ì•½ì¼"])
    combined["ê°œì›”ìˆ˜"] = (today.year - combined["ê³„ì•½ì¼"].dt.year) * 12 + (today.month - combined["ê³„ì•½ì¼"].dt.month)

    combined["ê±°ë¦¬_ê°€ì¤‘ì¹˜"] = np.exp(-3.0 * combined["ê±°ë¦¬_km"])
    combined["ì‹œê°„_ê°€ì¤‘ì¹˜"] = np.exp(-0.15 * combined["ê°œì›”ìˆ˜"])
    combined["ê°€ì¤‘ì¹˜"] = combined["ê±°ë¦¬_ê°€ì¤‘ì¹˜"] * combined["ì‹œê°„_ê°€ì¤‘ì¹˜"]

    return weighted_median(combined["ã¡ë‹¹ê°€ê²©"], combined["ê°€ì¤‘ì¹˜"])

address = "ì„œìš¸íŠ¹ë³„ì‹œ ê´€ì•…êµ¬ ë‚¨í˜„ë™ 602-28"
building_type = "ì•„íŒŒíŠ¸"

region, dong, jibun = parse_address(address)

# ë²•ì •ë™ ì½”ë“œ ì¡°íšŒ
lawd_cd = get_region_prefix(region)
df_coords = load_coords_by_building_type(building_type)
fallback_callback = lambda: fallback_strategy(address, lawd_cd, df_coords, building_type)

# ë©”ì¸ ì‹¤í–‰
price, per = estimate_real_estate_price(lawd_cd, dong, jibun, building_type, fallback_callback=fallback_callback)
print(f"\nğŸ“Š ìµœì¢… ì¶”ì • ì‹œì„¸: {price:,} ì›/ã¡ ({per})")